{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 500000  # Use a smaller vocabulary for quicker processing\n",
        "max_len = 200      # Shorter maximum sequence length\n",
        "num_samples = 5000 # Limit dataset size for faster execution\n",
        "\n",
        "# Load IMDB data (reduce size for speed)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "x_train, y_train = x_train[:num_samples], y_train[:num_samples]\n",
        "x_test, y_test = x_test[:1000], y_test[:1000]\n",
        "\n",
        "# Pad sequences to ensure equal length\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Build a smaller model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=max_len),  # Smaller embedding size\n",
        "    LSTM(32),  # Fewer LSTM units\n",
        "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the Model (fewer epochs)\n",
        "model.fit(x_train, y_train, epochs=2, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
        "\n",
        "# Decode function for review text\n",
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = {value: key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(text):\n",
        "    return \" \".join([reverse_word_index.get(i - 3, \"?\") for i in text])\n",
        "\n",
        "# Example Prediction with Decoded Review\n",
        "sample_review = x_test[0]  # First review in test set\n",
        "decoded_review = decode_review(sample_review)  # Decode it to text\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(tf.expand_dims(sample_review, axis=0))\n",
        "\n",
        "# Print the review and its predicted sentiment\n",
        "print(f\"Review: {decoded_review}\")\n",
        "print(f\"Sentiment: {'Positive' if prediction[0][0] > 0.5 else 'Negative'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZRNaSVKpO12",
        "outputId": "52bda033-5926-4423-9e7a-d1f04677d420"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 327ms/step - accuracy: 0.5501 - loss: 0.6891 - val_accuracy: 0.7330 - val_loss: 0.6263\n",
            "Epoch 2/2\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 312ms/step - accuracy: 0.7956 - loss: 0.4933 - val_accuracy: 0.7770 - val_loss: 0.4977\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7821 - loss: 0.4965\n",
            "Test Accuracy: 0.78\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
            "Review: ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\n",
            "Sentiment: Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rh3clv7GqPFD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}